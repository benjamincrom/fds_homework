{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benjamin Crom (Panther# 002-36-7349)\n",
    "__Mini-Project 2: Logistic Regression & Disaster Survival__<br>\n",
    "__CS 6980: Introduction to Data Science__<br>\n",
    "__29 January 2018__\n",
    "\n",
    "__Access this notebook online: https://goo.gl/mTEWkp__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](assignment.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot\n",
    "import numpy\n",
    "import pandas\n",
    "\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# ======================== LOAD DATA ========================\n",
    "csv_array = numpy.genfromtxt('titanic_data.csv', delimiter=',')\n",
    "data = csv_array[1:]\n",
    "Y = data[:,0]   # labels\n",
    "X = data[:,1:]  # feature vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](fig_2_2_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def l_beta(X, Y, beta):\n",
    "    return sum(\n",
    "        [\n",
    "            numpy.log(\n",
    "                (1 / (1 + numpy.exp(-1 * numpy.dot(numpy.transpose(beta), X[i]))))**Y[i] *\n",
    "                (1 - (1 / (1 + numpy.exp(-1 * numpy.dot(numpy.transpose(beta), X[i])))))**(1 - Y[i])\n",
    "            )\n",
    "            for i in range(len(X))\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](fig_2_3.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_l_beta(X, Y, beta):\n",
    "    return sum(\n",
    "        [\n",
    "            (Y[i] - (1 / (1 + numpy.exp(-1 * numpy.dot(numpy.transpose(beta), X[i]))))) * X[i]\n",
    "            for i in range(len(X))\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](fig_c.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_ascent(X, Y, beta, eta, tol):\n",
    "    last_l_beta = l_beta(X, Y, beta)\n",
    "    beta = beta + (eta * gradient_l_beta(X, Y, beta))\n",
    "    new_l_beta = l_beta(X, Y, beta)\n",
    "\n",
    "    while numpy.absolute(new_l_beta - last_l_beta) > tol:\n",
    "        last_l_beta = new_l_beta\n",
    "        beta = beta + (eta * gradient_l_beta(X, Y, beta))\n",
    "        new_l_beta = l_beta(X, Y, beta)\n",
    "        \n",
    "    return beta, l_beta(X, Y, beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](fig_d_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ======================= SPLIT DATA ========================\n",
    "is_training = numpy.random.randint(0, 5, len(X)) > 0\n",
    "is_test = numpy.invert(is_training)\n",
    "Y_train = Y[is_training]\n",
    "X_train = X[is_training]\n",
    "Y_test = Y[is_test]\n",
    "X_test = X[is_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](fig_e.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (30,) and (6,) not aligned: 30 (dim 0) != 6 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6810657e46c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0017\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_beta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_ascent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-349ea8301e23>\u001b[0m in \u001b[0;36mgradient_ascent\u001b[0;34m(X, Y, beta, eta, tol)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgradient_ascent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mlast_l_beta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml_beta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0meta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgradient_l_beta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnew_l_beta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml_beta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-1a15cc3a9d9f>\u001b[0m in \u001b[0;36ml_beta\u001b[0;34m(X, Y, beta)\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             )\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         ]\n\u001b[1;32m     10\u001b[0m     )\n",
      "\u001b[0;32m<ipython-input-2-1a15cc3a9d9f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             )\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         ]\n\u001b[1;32m     10\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (30,) and (6,) not aligned: 30 (dim 0) != 6 (dim 0)"
     ]
    }
   ],
   "source": [
    "# ==================== GRADIENT ASCENT ======================\n",
    "eta = 0.0000001\n",
    "tol = 0.0017\n",
    "beta = numpy.array([-0.03, 0.05, -0.02, -0.01, -0.0001, 0.018])\n",
    "beta, l_beta = gradient_ascent(X_train, Y_train, beta, eta, tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def classify_logReg(X, beta):\n",
    "    Y_hat = []\n",
    "    for i in range(len(X)):\n",
    "        y_1_val = (1 / (1 + numpy.exp(-1 * numpy.dot(numpy.transpose(beta), X[i]))))\n",
    "        y_0_val = (1 - (1 / (1 + numpy.exp(-1 * numpy.dot(numpy.transpose(beta), X[i])))))\n",
    "        \n",
    "        if y_1_val > y_0_val:\n",
    "            Y_hat.append(1.0)\n",
    "        else:\n",
    "            Y_hat.append(0.0)\n",
    "            \n",
    "    return numpy.array(Y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ========================== TEST ===========================\n",
    "Y_hat = classify_logReg(X_test, beta)\n",
    "error = sum(abs(Y_hat - Y_test)) / len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{eta} seems to best maximize l_beta. The largest l_beta I can achieve seems to be {round(l_beta, 2)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](fig_f.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(f'Coefficient vector beta: {beta}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(f'Accuracy: {round((1 - error)*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](fig_g.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ================== WOULD I HAVE SURVIVED ==================\n",
    "my_class = 2\n",
    "my_gender = 0\n",
    "my_age = 30\n",
    "my_ss = 1\n",
    "my_pc = 1\n",
    "idx = numpy.array([p for p in X if p[0] == my_class])\n",
    "my_fare = numpy.mean(idx, axis=0)[5]\n",
    "\n",
    "# Construct my feature vector\n",
    "my_x = numpy.array([my_class, my_gender, my_age, my_ss, my_pc, my_fare])\n",
    "\n",
    "# Classify\n",
    "my_y = classify_logReg([my_x], beta)\n",
    "\n",
    "if my_y:\n",
    "    print('I would have survived.')\n",
    "else:\n",
    "    print('I would not have survived.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_min_fare(v):\n",
    "    fare = 0\n",
    "    survived = 0\n",
    "\n",
    "    while not survived:\n",
    "        fare += 1\n",
    "        this_feature_vector = numpy.array([v[0], v[1], v[2], v[3], v[4], fare])\n",
    "        survived = classify_logReg([this_feature_vector], beta)\n",
    "        \n",
    "    return fare\n",
    "\n",
    "benjamin_crom_feature_vector = numpy.array([2, 0, 30, 1, 1, 0])\n",
    "min_fare = get_min_fare(benjamin_crom_feature_vector)\n",
    "print(f'I would have survived if I paid {min_fare} for my fare.')\n",
    "\n",
    "benjamin_crom_feature_vector = numpy.array([1, 0, 30, 1, 1, 0])\n",
    "min_fare = get_min_fare(benjamin_crom_feature_vector)\n",
    "print(f'I would have survived if I sat in first class and paid {min_fare} for my fare.')\n",
    "\n",
    "benjamin_crom_feature_vector = numpy.array([1, 0, 30, 0, 1, 0])\n",
    "min_fare = get_min_fare(benjamin_crom_feature_vector)\n",
    "print(f'I would have survived if I sat in first class, had no spouse aboard, and paid {min_fare} for my fare.')\n",
    "\n",
    "print('Having parents/children aboard has very minimal impact on survival.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](fig_h.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ========== VISUALIZE 3 MOST IMPORTANT VARIABLES ===========\n",
    "def survived_by_feature(feature_index, feature_x_label):\n",
    "    survived_counter = collections.Counter([p[feature_index] for p in X[Y == 1]])\n",
    "    total_counter = collections.Counter([p[feature_index] for p in X])\n",
    "    ratio_dict = {key: survived_counter[key] / total_counter[key]\n",
    "                  for key in total_counter}\n",
    "\n",
    "    tuple_list = sorted(ratio_dict.items(), key=lambda tup: tup[0])\n",
    "    x = [t[0] for t in tuple_list]\n",
    "    y = [t[1]*100 for t in tuple_list]\n",
    "\n",
    "    ax = matplotlib.pyplot.figure().gca()\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    matplotlib.pyplot.bar(x, y)\n",
    "    matplotlib.pyplot.xlabel(feature_x_label)\n",
    "    matplotlib.pyplot.ylabel('% survived')\n",
    "    matplotlib.pyplot.show()\n",
    "\n",
    "print('Class, Gender, and Age have the biggest impact on survival per invidual unit of change:')\n",
    "for feature_index, feature_x_label in [(0, 'Class'), (1, 'Gender'), (2, 'Age')]:\n",
    "    survived_by_feature(feature_index, feature_x_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
